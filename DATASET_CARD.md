# Dataset Card

## Описание данных
Набор данных содержит тексты комментариев/постов из ВКонтакте, размеченные по тематикам/тональности.

## Происхождение
*   **Источник:** Спаршено API ВКонтакте

## Структура и Сплиты
Общий размер датасета: 310000 постов.
Данные разделены на выборки (фиксированный random seed = 42):

| Сплит | Доля |
|:------|:-----|
| **Train** | 80% |
| **Test** | 20% |

## Предобработка (Preprocessing)
Пайплайн обработки данных (`src/data/make_dataset.py`) включает:
1.  **Очистка:** Удаление HTML-тегов, спецсимволов, ссылок
2.  **Нормализация:** Приведение к нижнему регистру, лемматизация
3.  **Токенизация:** Разбиение на слова
4.  **Удаление стоп-слов:** `nltk.corpus.stopwords`
5.  **Векторизация:** `cointegrated/rubert2-tiny`

## Как получить данные
Для загрузки актуальной версии данных используйте DVC:
